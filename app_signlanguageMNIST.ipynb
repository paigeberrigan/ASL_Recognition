{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the project root is in the system path\n",
    "project_root = os.path.abspath(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data and models\n",
    "train_csv_path = os.path.join(project_root, \"Extracted_SignLanguageMNIST\", \"sign_mnist_train.csv\")\n",
    "test_csv_path = os.path.join(project_root, \"Extracted_SignLanguageMNIST\", \"sign_mnist_test.csv\")\n",
    "\n",
    "# Create label mapping (0 -> A, 1 -> B, ..., 25 -> Z)\n",
    "label_mapping = {i: chr(65 + i) for i in range(26)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "train_data = pd.read_csv(train_csv_path)\n",
    "test_data = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 26\n",
    "\n",
    "# Load models (caching to avoid reloading)\n",
    "loaded_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_type, num_classes, model_path=None, device='cpu'):\n",
    "    model_type = model_type.lower()\n",
    "    if model_type == \"resnet18\":\n",
    "        model = models.resnet18(weights=None)\n",
    "    elif model_type == \"resnet50\":\n",
    "        model = models.resnet50(weights=None)\n",
    "    elif model_type == \"custom\":\n",
    "        model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 56 * 56, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'resnet18', 'resnet50', or 'custom'.\")\n",
    "\n",
    "    if \"resnet\" in model_type:\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    if model_path:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(f\"Model weights loaded from {model_path}\")\n",
    "    else:\n",
    "        print(f\"Using pretrained weights for {model_type}\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "model_paths = {\n",
    "    \"resnet18\": os.path.join(project_root, \"saved_models\", \"trained_resnet18.pth\"),\n",
    "    \"resnet50\": os.path.join(project_root, \"saved_models\", \"trained_resnet50.pth\"),\n",
    "    \"custom\": os.path.join(project_root, \"saved_models\", \"trained_custom.pth\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = {\n",
    "    \"resnet18\": os.path.join(project_root, \"saved_models\", \"trained_resnet18.pth\"),\n",
    "    \"resnet50\": os.path.join(project_root, \"saved_models\", \"trained_resnet50.pth\"),\n",
    "    \"custom\": os.path.join(project_root, \"saved_models\", \"trained_custom.pth\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sample_image(sample_index):\n",
    "    data = train_data\n",
    "    labels = data.iloc[:, 0].values\n",
    "    images = data.iloc[:, 1:].values\n",
    "\n",
    "    if sample_index >= len(images):\n",
    "        raise IndexError(f\"Sample index {sample_index} is out of range.\")\n",
    "\n",
    "    label = labels[sample_index]\n",
    "    image_data = images[sample_index].reshape(28, 28).astype(\"uint8\")\n",
    "    image = Image.fromarray(image_data).convert(\"RGB\")\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_model(model_choice, image):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_choice_lower = model_choice.lower()\n",
    "\n",
    "    # Preprocess the image\n",
    "    input_tensor = preprocess_image(image).to(device)\n",
    "\n",
    "    # Load the model from cache or load and cache it\n",
    "    if model_choice_lower in loaded_models:\n",
    "        model = loaded_models[model_choice_lower]\n",
    "    else:\n",
    "        model_path = model_paths.get(model_choice_lower)\n",
    "        if not model_path:\n",
    "            raise ValueError(f\"Invalid model choice: {model_choice}\")\n",
    "        model = load_model(model_choice_lower, num_classes=num_classes, model_path=model_path, device=device)\n",
    "        loaded_models[model_choice_lower] = model  # Cache the loaded model\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "        predicted_class = np.argmax(probabilities)\n",
    "        confidence_scores = probabilities\n",
    "\n",
    "    return predicted_class, confidence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio Interface with improved layout\n",
    "def create_dashboard():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"# Sign Language Recognition Dashboard\")\n",
    "        gr.Markdown(\"Use this app to explore different models for recognizing sign language letters.\")\n",
    "        \n",
    "        with gr.Tabs():\n",
    "            with gr.TabItem(\"Predict\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=1):\n",
    "                        gr.Markdown(\"### Model Selection\")\n",
    "                        model_choice = gr.Radio(\n",
    "                            [\"ResNet18\", \"ResNet50\", \"Custom\"],\n",
    "                            label=\"Model\",\n",
    "                            value=\"ResNet18\"\n",
    "                        )\n",
    "                        gr.Markdown(\"### Select Sample Image\")\n",
    "                        sample_index = gr.Slider(\n",
    "                            0, len(train_data) - 1,\n",
    "                            step=1,\n",
    "                            label=\"Sample Index\",\n",
    "                            value=0\n",
    "                        )\n",
    "                        gr.Markdown(\"### Or Upload Your Own Image\")\n",
    "                        upload_image = gr.Image(type=\"pil\", label=\"Upload Image (Optional)\")\n",
    "                    with gr.Column(scale=1):\n",
    "                        image_display = gr.Image(\n",
    "                            label=\"Input Image\",\n",
    "                            type=\"pil\",\n",
    "                            interactive=False,\n",
    "                            width=224,\n",
    "                            height=224\n",
    "                        )\n",
    "                        prediction_text = gr.Textbox(\n",
    "                            label=\"Prediction\",\n",
    "                            interactive=False\n",
    "                        )\n",
    "                        actual_label_text = gr.Textbox(\n",
    "                            label=\"Actual Label\",\n",
    "                            interactive=False\n",
    "                        )\n",
    "                gr.Markdown(\"### Prediction Confidence\")\n",
    "                confidence_plot = gr.Plot(\n",
    "                    label=\"Confidence Scores\"\n",
    "                )\n",
    "            with gr.TabItem(\"About\"):\n",
    "                gr.Markdown(\"\"\"\n",
    "                ### About This Application\n",
    "\n",
    "                This Sign Language Recognition Dashboard is developed to demonstrate the capabilities of different neural network architectures in recognizing American Sign Language (ASL) letters. \n",
    "                \n",
    "                This dashboard was delveloped for a cummulative project for Fanshawe College (London, Onatrio), Deep Learning with Pytorch\n",
    "                \n",
    "                The application allows users to:\n",
    "\n",
    "                - **Explore different models**: Compare the performance of ResNet18, ResNet50, and a custom CNN model.\n",
    "                - **Visualize predictions**: View the predicted letter and confidence scores for each class.\n",
    "                - **Upload custom images**: Test the models with your own images of ASL letters that have not been included in the training set!\n",
    "\n",
    "\n",
    "                #### Dataset\n",
    "\n",
    "                The models are trained on the [Sign Language MNIST](https://www.kaggle.com/datamunge/sign-language-mnist) dataset, which contains images of ASL letters represented in a format similar to the original MNIST dataset.\n",
    "\n",
    "                #### Acknowledgments\n",
    "\n",
    "                - **Dataset**: Thanks to [Kaggle](https://www.kaggle.com/) and the contributors for providing the Sign Language MNIST dataset.\n",
    "                - **Libraries Used**: PyTorch, Torchvision, Gradio, Plotly, NumPy, and Pandas.\n",
    "\n",
    "                \"\"\")\n",
    "        \n",
    "        # Add GitHub link at the bottom\n",
    "        gr.Markdown(\"\"\"\n",
    "        ---\n",
    "        Developed by [Paige Berrigan](https://github.com/paigeberrigan). View the project on [GitHub](https://github.com/yourusername/yourrepository).\n",
    "        \"\"\")\n",
    "\n",
    "        # Define the interaction with live updates\n",
    "        def on_change(model_choice, sample_index, upload_image):\n",
    "            if upload_image is not None:\n",
    "                image = upload_image\n",
    "                actual_label = \"N/A\"\n",
    "            else:\n",
    "                image, actual_label_idx = fetch_sample_image(int(sample_index))\n",
    "                actual_label = label_mapping.get(actual_label_idx, \"Unknown\")\n",
    "\n",
    "            # Resize the image for display purposes\n",
    "            image_display_resized = image.resize((224, 224), Image.NEAREST)\n",
    "\n",
    "            predicted_class, confidence_scores = predict_with_model(model_choice, image)\n",
    "            predicted_letter = label_mapping.get(predicted_class, \"Unknown\")\n",
    "\n",
    "            # Prepare the confidence bar graph using Plotly\n",
    "            labels = [label_mapping[i] for i in range(num_classes)]\n",
    "            import plotly.graph_objects as go\n",
    "            fig = go.Figure([go.Bar(x=labels, y=confidence_scores)])\n",
    "            fig.update_layout(\n",
    "                title='Prediction Confidence',\n",
    "                xaxis_title='Classes',\n",
    "                yaxis_title='Confidence',\n",
    "                xaxis_tickangle=-45,\n",
    "                height=400\n",
    "            )\n",
    "\n",
    "            return image_display_resized, f\"Predicted: {predicted_letter}\", f\"Actual: {actual_label}\", fig\n",
    "\n",
    "        # make sure the app is updating live\n",
    "        inputs = [model_choice, sample_index, upload_image]\n",
    "        outputs = [image_display, prediction_text, actual_label_text, confidence_plot]\n",
    "        model_choice.change(on_change, inputs=inputs, outputs=outputs)\n",
    "        sample_index.change(on_change, inputs=inputs, outputs=outputs)\n",
    "        upload_image.change(on_change, inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paige\\AppData\\Local\\Temp\\ipykernel_23400\\1750226274.py:28: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded from c:\\Users\\paige\\OneDrive\\Desktop\\6147 - PYTORCH\\Capstone_SignLanguageMNIST\\saved_models\\trained_resnet50.pth\n",
      "Model weights loaded from c:\\Users\\paige\\OneDrive\\Desktop\\6147 - PYTORCH\\Capstone_SignLanguageMNIST\\saved_models\\trained_resnet18.pth\n",
      "Model weights loaded from c:\\Users\\paige\\OneDrive\\Desktop\\6147 - PYTORCH\\Capstone_SignLanguageMNIST\\saved_models\\trained_custom.pth\n"
     ]
    }
   ],
   "source": [
    "# launch the dashboard\n",
    "demo = create_dashboard()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
